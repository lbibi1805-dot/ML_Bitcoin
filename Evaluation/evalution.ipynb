{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages.(Uncomment the below line if you have not install necessary libraries)\n",
    "# pip install pandas numpy matplotlib scikit-learn joblib lightgbm xgboost seaborn scipy\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.preprocessing import OneHotEncoder      \n",
    "from sklearn.model_selection import KFold   \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib \n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Additional useful imports\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 1: DATA COLLECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data = yf.download('BTC-USD', start='2010-01-01', end='2024-10-10', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header\n",
    "print(\"______________________Overview of the Dataset_______________________\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print out the crawled data information\n",
    "print(btc_data.head(4000),\"\\n\")\n",
    "print(btc_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 2: Prepare the incidicators**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1: Add indicators to the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions to create the indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add indicators (e.g., moving averages, RSI)\n",
    "def add_indicators(df):\n",
    "    # Moving Averages (MA)\n",
    "    df['MA_10'] = df['Close'].rolling(window=10).mean()  # 10-day Moving Average\n",
    "    df['MA_50'] = df['Close'].rolling(window=50).mean()  # 50-day Moving Average\n",
    "    df['MA_200'] = df['Close'].rolling(window=200).mean()  # 200-day Moving Average\n",
    "    df['MA_20'] = df['Close'].rolling(window=20).mean()  # 20-day Moving Average (needed for Bollinger Bands)\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    delta = df['Close'].diff(1)\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands (Upper and Lower Bands) - Uses MA_20\n",
    "    df['BB_upper'] = df['MA_20'] + 2 * df['Close'].rolling(window=20).std()\n",
    "    df['BB_lower'] = df['MA_20'] - 2 * df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    # Exponential Moving Average (EMA)\n",
    "    df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()  # 10-day Exponential Moving Average\n",
    "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()  # 50-day Exponential Moving Average\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Việc xử lý các giá trị NaN trong dữ liệu là một bước quan trọng trong quy trình tiền xử lý dữ liệu. Câu hỏi về việc drop (loại bỏ) các hàng với giá trị NaN hay điền các giá trị thay thế (imputation) phụ thuộc vào loại dữ liệu, bài toán cụ thể, và cách bạn muốn mô hình học từ dữ liệu.\n",
    "\n",
    "Lý do nên drop (loại bỏ) các hàng với giá trị NaN:\n",
    "Dữ liệu thiếu có thể không đáng tin cậy: Nếu giá trị thiếu chiếm một phần nhỏ và không ảnh hưởng đến mẫu dữ liệu tổng thể, việc loại bỏ có thể tránh được việc tạo ra thông tin giả mạo hoặc làm méo mó dữ liệu thật.\n",
    "\n",
    "Chỉ báo kỹ thuật cần các giá trị liền kề: Trong trường hợp các chỉ báo như Trung bình động (MA), RSI, hay Bollinger Bands, việc điền giá trị có thể không hợp lý vì các chỉ báo này phụ thuộc vào các giá trị thực tế liền kề. Ví dụ, điền vào một giá trị NaN trong Trung bình động có thể làm sai lệch thông tin về xu hướng.\n",
    "\n",
    "Dữ liệu thiếu không nhiều: Nếu chỉ có một số hàng chứa NaN và số lượng này không đáng kể so với toàn bộ dữ liệu, việc loại bỏ các hàng đó sẽ không ảnh hưởng lớn đến kết quả dự đoán, nhưng lại giúp tránh sự phức tạp không cần thiết trong việc điền giá trị.\n",
    "\n",
    "Lý do nên impute (điền vào giá trị thay thế) các giá trị NaN:\n",
    "Bảo toàn kích thước dữ liệu: Nếu dữ liệu chứa nhiều hàng với NaN, việc loại bỏ các hàng này có thể làm giảm kích thước bộ dữ liệu đáng kể, dẫn đến mô hình kém hiệu quả hơn hoặc không có đủ thông tin để học.\n",
    "\n",
    "Tránh mất thông tin: Loại bỏ các hàng có thể dẫn đến việc bỏ sót những thông tin quan trọng. Nếu các giá trị NaN xảy ra rải rác, việc điền giá trị vào có thể là lựa chọn hợp lý hơn.\n",
    "\n",
    "Phương pháp điền giá trị thông minh: Bạn có thể sử dụng các phương pháp điền giá trị tiên tiến hơn, như:\n",
    "\n",
    "Mean/Median/Mode imputation: Điền giá trị trung bình, trung vị hoặc mode của cột.\n",
    "Forward fill hoặc Backward fill: Điền giá trị NaN bằng các giá trị trước hoặc sau nó.\n",
    "KNN imputation: Sử dụng KNN để dự đoán giá trị thiếu dựa trên các điểm dữ liệu lân cận.\n",
    "Iterative Imputer: Điền vào giá trị thiếu bằng cách dùng các cột khác để dự đoán giá trị của nó.\n",
    "Ví dụ, nếu giá trị NaN xuất hiện trong cột 'Close', bạn có thể điền giá trị bằng giá trị trung bình của các ngày liền trước và liền sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add indicators to the dataset\n",
    "btc_data = add_indicators(btc_data)\n",
    "\n",
    "# Display the updated data with added indicators\n",
    "print(\"\\n______________________Dataset with Added Indicators_______________________\")\n",
    "print(\"\\n\")\n",
    "print(btc_data.tail(10))  # Show the last 10 rows to check if indicators are added\n",
    "\n",
    "# Drop rows with NaN values (due to moving averages and RSI calculations)\n",
    "btc_data.dropna(inplace=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(btc_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 3: Plotting to gain some insight of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting price data along with Moving Averages\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(btc_data.index, btc_data['Close'], label='Close Price', color='blue', alpha=0.6)\n",
    "plt.plot(btc_data.index, btc_data['MA_10'], label='MA_10', color='green', linestyle='--')\n",
    "plt.plot(btc_data.index, btc_data['MA_50'], label='MA_50', color='orange', linestyle='--')\n",
    "plt.plot(btc_data.index, btc_data['MA_200'], label='MA_200', color='red', linestyle='--')\n",
    "plt.title('Bitcoin Price with Moving Averages (10, 50, 200 Days)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting RSI (Relative Strength Index)\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(btc_data.index, btc_data['RSI'], label='RSI', color='purple')\n",
    "plt.axhline(70, linestyle='--', alpha=0.5, color='red')  # Overbought level\n",
    "plt.axhline(30, linestyle='--', alpha=0.5, color='green')  # Oversold level\n",
    "plt.title('Relative Strength Index (RSI)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('RSI Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting Bollinger Bands along with the Closing Price\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(btc_data.index, btc_data['Close'], label='Close Price', color='blue', alpha=0.6)\n",
    "plt.plot(btc_data.index, btc_data['BB_upper'], label='Bollinger Upper Band', color='orange', linestyle='--')\n",
    "plt.plot(btc_data.index, btc_data['BB_lower'], label='Bollinger Lower Band', color='orange', linestyle='--')\n",
    "plt.fill_between(btc_data.index, btc_data['BB_lower'], btc_data['BB_upper'], color='orange', alpha=0.2)\n",
    "plt.title('Bollinger Bands with Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 4: Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1. Drop unrelated columns using MI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.1. Prepare the data for MI analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = btc_data.drop(['Close'], axis=1)  # Drop the 'Close' column (target)\n",
    "target = btc_data['Close']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.2. Use mutual_info_regression to calculate MI between features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mutual_info_regression to calculate MI between features and target\n",
    "mi = mutual_info_regression(features, target, discrete_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.3. Create a DataFrame to display feature importance using MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df = pd.DataFrame({'Feature': features.columns, 'MI_Score': mi})\n",
    "mi_df = mi_df.sort_values(by='MI_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the MI scores\n",
    "print(\"\\n______________________Mutual Information Scores_______________________\")\n",
    "print(mi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.3. Keep features with non-zero MI score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep features with non-zero MI score\n",
    "important_features = mi_df[mi_df['MI_Score'] > 0.05]['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.4. Drop unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data_clean = btc_data[['Close'] + important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n______________________Data After Dropping Unrelated Columns_______________________\")\n",
    "print(btc_data_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2. Shift label for future predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = -1\n",
    "btc_data['Close'] = btc_data['Close'].shift(k)\n",
    "\n",
    "# Drop the rows with NaN values that were created by the shift\n",
    "btc_data = btc_data.dropna()\n",
    "\n",
    "# Assesment after the drop:\n",
    "print(\"\\n_____________________Data Asessment After Shifting_______________________\\n\")\n",
    "print(btc_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3. Split training the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_set, test_set = train_test_split(btc_data, test_size=0.2, random_state=42)  \n",
    "\n",
    "# Print out some information of the split of the training set and the test set\n",
    "print('\\n____________ Split training and test set ____________')     \n",
    "print(len(train_set), \"training +\", len(test_set), \"test examples\")\n",
    "print(train_set.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 Separate labels from data, since we do not process label values (already processed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels from data\n",
    "X_train = train_set.drop(columns=['Close'])\n",
    "y_train = train_set['Close']\n",
    "X_test = test_set.drop(columns=['Close'])\n",
    "y_test = test_set['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5. Define transfomer and fit the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    # Constructor takes a list of column names to select\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names  # Store the list of column names\n",
    "\n",
    "    # The fit method doesn't need to do anything, it just returns self\n",
    "    # to be compatible with scikit-learn's pipeline process\n",
    "    def fit(self, dataframe, labels=None):\n",
    "        return self\n",
    "\n",
    "    # The transform method selects columns from the DataFrame based on the list of column names\n",
    "    # and returns the values as a NumPy array\n",
    "    def transform(self, dataframe):\n",
    "        return dataframe[self.feature_names].values  # Select and return columns as a NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features\n",
    "numerical_features = ['Open', 'High', 'Low', 'Volume', 'Adj Close', 'MA_10', 'MA_50', 'MA_200', 'RSI', 'MA_20', 'BB_upper', \n",
    "                      'BB_lower', 'EMA_10', 'EMA_50']\n",
    "\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(numerical_features)),  # Select numeric columns\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"median\")),  # Fill missing values with median\n",
    "    ('std_scaler', StandardScaler(with_mean=True, with_std=True))  # Normalize to zero mean and unit variance\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6. Run the pipeline to process training data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_set_val = num_pipeline.fit_transform(train_set)\n",
    "\n",
    "# Fit the pipeline on training data and transform both training and test data\n",
    "X_train = num_pipeline.fit_transform(X_train)\n",
    "X_test = num_pipeline.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train, columns=numerical_features)\n",
    "X_test = pd.DataFrame(X_test, columns=numerical_features)\n",
    "\n",
    "print('\\n____________ Processed feature values ____________')\n",
    "print(processed_train_set_val[:3, :]) # Print out some of the first rows of the training dataset after fit_transforming\n",
    "print(processed_train_set_val.shape)  # Print out the statistics of the training set\n",
    "joblib.dump(num_pipeline, r'models/num_pipeline.pkl')   #  Save the pipeline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 5: TRAIN AND EVALUATE MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2score_and_rmse(model, train_data, labels): \n",
    "    r2score = model.score(train_data, labels)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    prediction = model.predict(train_data)\n",
    "    mse = mean_squared_error(labels, prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return r2score, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_model(model, model_name = \"\"):\n",
    "    # NOTE: sklearn.joblib faster than pickle of Python\n",
    "    # INFO: can store only ONE object in a file\n",
    "    if model_name == \"\": \n",
    "        model_name = type(model).__name__\n",
    "    joblib.dump(model,'models/' + model_name + '_model.pkl')\n",
    "    print(f\"Model successfully saved as \" + model_name + '_model.pkl')\n",
    "    \n",
    "def load_model(model_name):\n",
    "    # Load objects into memory\n",
    "    #del model\n",
    "    model = joblib.load('models/' + model_name + '_model.pkl')\n",
    "    #print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1. Try LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor() #fix here\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________ LGBMRegressor ____________')\n",
    "\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "\n",
    "# Predict labels for some test instances\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2. Try XGBoost model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor() #fix here\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________ XGBoost_Regressor ____________')\n",
    "\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "\n",
    "# Predict labels for some test instances\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3. Try Decision Tree.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Cây quyết định dễ bị overfitting: Nếu bạn không điều chỉnh độ sâu tối đa của cây (max_depth), mô hình có thể quá khớp với dữ liệu huấn luyện, dẫn đến điểm R² gần 1 và RMSE rất thấp trên tập huấn luyện. Tuy nhiên, khi dự đoán trên dữ liệu kiểm tra, mô hình sẽ không hoạt động tốt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth xác định độ sâu tối đa của cây quyết định. Điều này có nghĩa là cây sẽ không phát triển thêm các nhánh mới sau khi đạt đến chiều cao tối đa này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Việc lựa chọn giá trị tối ưu cho max_depth thường được thực hiện thông qua các phương pháp tìm kiếm như Grid Search hoặc Random Search, kết hợp với k-fold cross-validation để tìm ra cấu hình tốt nhất cho mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngăn chặn Overfitting: Đặt giá trị max_depth thấp hơn có thể giúp ngăn ngừa việc cây quyết định quá khớp với dữ liệu huấn luyện, từ đó cải thiện khả năng tổng quát của mô hình trên dữ liệu kiểm tra.\n",
    "\n",
    "Giảm Hiệu suất: Nếu max_depth quá thấp, mô hình có thể không đủ phức tạp để nắm bắt các mối quan hệ trong dữ liệu, dẫn đến hiệu suất kém (underfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(max_depth = 10) # ĐÃ SỬA\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________DecisionTreeRegressor____________')\n",
    "\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "\n",
    "# Predict labels for some test instances\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4. Try Polynomial Regression (in-lecture).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sử dụng PolynomialFeatures kết hợp với một mô hình hồi quy\n",
    "# degree = 10  \n",
    "# model = Pipeline([\n",
    "#     ('poly_features', PolynomialFeatures(degree=degree)),\n",
    "#     ('lin_reg', LinearRegression())\n",
    "# ])\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# print('\\n____________PolynomialRegressor____________')\n",
    "\n",
    "# r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "# print('\\nR2 score (on training data, best=1):', r2score)\n",
    "# print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "# # Predict labels for some test instances\n",
    "# print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "# print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "# store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.5. Try Linear Regressor (in-lecture).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression() #fix here\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________LinearRegressor____________')\n",
    "\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "# Predict labels for some test instances\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.6. Try Random Forest (in-lecture).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 100) # ĐÃ SỬA\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________RandomForestRegressor____________')\n",
    "\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "# Predict labels for some test instances\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.7. Try K-Nearest-Neighbor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=5)  # ADJUST\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________KNeighborsRegressor____________')\n",
    "\n",
    "# Tính toán r2 score và rmse\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "\n",
    "# Dự đoán nhãn cho một số mẫu thử nghiệm\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:2]))\n",
    "print(\"Labels:      \", list(y_test[:2]))\n",
    "\n",
    "# Lưu mô hình đã huấn luyện\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LƯU Ý PHẢI ĐIỀU CHÌNH CÁC HỆ SỐ ĐỂ ĐƯA RA KẾT QUẢ TỐT NHẤT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 6: K-CROSS VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot(model, model_name, X_train, y_train, cv):\n",
    "    y_train_pred = cross_val_predict(model, X_train, y_train, cv=cv)\n",
    "    nmse_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-nmse_scores)\n",
    "    residuals = y_train - y_train_pred\n",
    "\n",
    "    joblib.dump(rmse_scores, 'saved_objects/' + model_name + '_rmse.pkl')\n",
    "    joblib.dump(residuals, 'saved_objects/' + model_name + '_residuals.pkl')  # Lưu residuals\n",
    "    \n",
    "    print(f\"{model_name} RMSE: \", rmse_scores)\n",
    "    print(f\"Avg. RMSE: \", np.mean(rmse_scores), '\\n')\n",
    "    \n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'Residual Distribution for {model_name} Regression')\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_print_rmse_with_plot(model_name, residuals):\n",
    "    # Load RMSE scores\n",
    "    rmse_scores = joblib.load('saved_objects/' + model_name + '_rmse.pkl')\n",
    "    \n",
    "    # Load residuals\n",
    "    residuals = joblib.load('saved_objects/' + model_name + '_residuals.pkl')\n",
    "    \n",
    "    # Print RMSE and average RMSE\n",
    "    print(f\"{model_name} RMSE: \", rmse_scores)\n",
    "    print(f\"Avg. RMSE: \", mean(rmse_scores), '\\n')\n",
    "    \n",
    "    # Plot residual distribution\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'Residual Distribution for {model_name} Regression')\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n____________ K-fold cross validation ____________')\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=37) # cv data generator\n",
    "\n",
    "run_new_evaluation = 1\n",
    "if run_new_evaluation == 1:\n",
    "    models = [\n",
    "        (LinearRegression(), \"LinearRegression\"),\n",
    "        (Pipeline([('poly_features', PolynomialFeatures(degree=10)), ('lin_reg', LinearRegression())]), \"PolynomialRegression\"),\n",
    "        (DecisionTreeRegressor(max_depth=10), \"DecisionTreeRegressor\"),\n",
    "        (lgb.LGBMRegressor(), \"LightGBM\"),\n",
    "        (XGBRegressor(), \"XGBoostRegressor\"),\n",
    "        (RandomForestRegressor(n_estimators=100), \"RandomForestRegressor\"),\n",
    "        (KNeighborsRegressor(n_neighbors=5), \"KNeighbour\"),\n",
    "    ]\n",
    "    \n",
    "    for model, model_name in models:\n",
    "        evaluate_and_plot(model, model_name, X_train, y_train, cv)\n",
    "\n",
    "else:\n",
    "    model_names = [\n",
    "        \"LinearRegression\",\n",
    "        \"PolynomialRegression\",\n",
    "        \"DecisionTreeRegressor\",\n",
    "        \"RandomForestRegressor\",\n",
    "        \"LightGBM\",\n",
    "        \"XGBoostRegressor\",\n",
    "        \"KNeighbour\"\n",
    "    ]\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        load_and_print_rmse_with_plot(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
